{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lekcja 31: Wprowadzenie do LangChain i jego architektury**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Wstęp**\n",
    "LangChain to framework, który **upraszcza tworzenie aplikacji AI** opartych na **LLMs**. Umożliwia:\n",
    "- **Łączenie modeli AI z danymi**\n",
    "- **Tworzenie chatbotów**\n",
    "- **Automatyzację procesów**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Instalacja LangChain**\n",
    "Komórka 1: Instalacja wymaganych bibliotek (uruchom tylko raz, jeśli ich nie masz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (1.0.1)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (0.8.4)\n",
      "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
      "  Using cached langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.11.12-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Using cached numpy-2.2.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (2.160.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.67.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
      "Using cached aiohttp-3.11.12-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
      "Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Using cached numpy-2.2.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Installing collected packages: filetype, zstandard, tenacity, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain-google-genai\n",
      "Successfully installed SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 filetype-1.2.0 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.18 langchain-core-0.3.34 langchain-google-genai-2.0.9 langchain-text-splitters-0.3.6 langsmith-0.3.8 multidict-6.1.0 numpy-2.2.2 orjson-3.10.15 propcache-0.2.1 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.18.3 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv langchain langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Podstawowa architektura LangChain**\n",
    "LangChain składa się z 3 głównych komponentów:\n",
    "1. **LLMs** → Model językowy (np. GPT-4).\n",
    "2. **Prompt Engineering** → Tworzenie skutecznych zapytań.\n",
    "3. **Łańcuchy (Chains)** → Automatyczne wykonywanie sekwencji operacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Przykład kodu – użycie LangChain do generowania tekstu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komórka 2: Import bibliotek, załadowanie klucza API i inicjalizacja modelu Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "# Załaduj zmienne środowiskowe z pliku .env\n",
    "load_dotenv()\n",
    "\n",
    "# Pobierz klucz API Google z zmiennej środowiskowej\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Sprawdź czy klucz API Google został pobrany\n",
    "if google_api_key is None:\n",
    "    raise ValueError(\"Nie znaleziono klucza API Google. Upewnij się, że ustawiłeś zmienną środowiskową GOOGLE_API_KEY w pliku .env.\")\n",
    "\n",
    "# Ustaw klucz API i zainicjuj model ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komórka 3: Definicja promptu i uruchomienie łańcucha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain to framework ułatwiający tworzenie aplikacji opartych na dużych modelach językowych (LLM). Zapewnia on zestaw abstrakcji i narzędzi upraszczających pracę z LLM, pozwalając na budowę bardziej zaawansowanych i złożonych aplikacji.\n",
      "\n",
      "Oto główne elementy działania LangChain:\n",
      "\n",
      "**1. Modele:**\n",
      "\n",
      "* **LLMs:** LangChain obsługuje integrację z różnymi dostawcami LLM, takimi jak OpenAI, Hugging Face, Cohere i innymi. Można łatwo przełączać się między modelami i eksperymentować z różnymi architekturami.\n",
      "* **Chat Models:**  LangChain oferuje specjalizowane wsparcie dla modeli konwersacyjnych, pozwalając na budowanie chatbotów i asystentów. Umożliwia to zarządzanie historią konwersacji i definiowanie różnych person dla botów.\n",
      "* **Text Embedding Models:**  LangChain integruje się z modelami generującymi wektory osadzeń tekstu, co umożliwia porównywanie semantyczne tekstów i wyszukiwanie informacji.\n",
      "\n",
      "**2. Łańcuchy (Chains):**\n",
      "\n",
      "* **Sekwencyjne:** Łańcuchy sekwencyjne wykonują serię operacji jedna po drugiej.  Wynik jednego kroku jest przekazywany jako wejście do kolejnego.  Przykładowo, można stworzyć łańcuch, który najpierw podsumowuje tekst, a następnie tłumaczy go na inny język.\n",
      "* **Równoległe:**  Łańcuchy równoległe wykonują wiele operacji jednocześnie.  Przykładowo, można wysłać ten sam tekst do kilku różnych LLM i porównać ich odpowiedzi.\n",
      "\n",
      "**3. Indeksy:**\n",
      "\n",
      "* **Wektoryzacja i wyszukiwanie:** LangChain ułatwia tworzenie indeksów wektorowych dokumentów, co umożliwia szybkie i efektywne wyszukiwanie informacji na podstawie semantycznego podobieństwa.\n",
      "* **Łączenie z bazami danych:**  LangChain pozwala na łączenie LLM z zewnętrznymi źródłami danych, takimi jak bazy danych SQL lub dokumenty.  Umożliwia to LLM dostęp do informacji spoza ich własnej wiedzy.\n",
      "\n",
      "**4. Pamięć:**\n",
      "\n",
      "* **Zachowywanie kontekstu:** LangChain oferuje mechanizmy pamięci, które pozwalają LLM na zapamiętywanie poprzednich interakcji i wykorzystywanie tej informacji w kolejnych odpowiedziach.  To kluczowe dla budowania spójnych i kontekstualnych konwersacji.\n",
      "* **Różne typy pamięci:**  LangChain obsługuje różne typy pamięci, takie jak pamięć krótkotrwała (np. ostatnie kilka wypowiedzi) i długotrwała (np. informacje o użytkowniku).\n",
      "\n",
      "**5. Callbacks:**\n",
      "\n",
      "* **Monitorowanie i debugowanie:** Callbacks pozwalają na monitorowanie działania łańcuchów i zbieranie informacji o ich wykonaniu.  Ułatwia to debugowanie i optymalizację aplikacji.\n",
      "\n",
      "**Podsumowując:**\n",
      "\n",
      "LangChain działa poprzez łączenie różnych komponentów, takich jak modele LLM, łańcuchy, indeksy i pamięć, w celu tworzenia zaawansowanych aplikacji opartych na języku.  Framework ten upraszcza proces budowania, testowania i wdrażania tych aplikacji, oferując elastyczność i modularność.  Dzięki LangChain, deweloperzy mogą skupić się na logice aplikacji, zamiast na szczegółach technicznych integracji z LLM.\n"
     ]
    }
   ],
   "source": [
    "# Utwórz prompt template\n",
    "template = \"Jak działa LangChain?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Stwórz łańcuch\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Wykonaj zapytanie i uzyskaj odpowiedź\n",
    "response = chain.invoke({})\n",
    "\n",
    "# Wyświetl odpowiedź\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyjaśnienie:\n",
    "\n",
    "    Komórka 1: Instaluje wymagane biblioteki. Uruchom ją tylko raz, chyba że chcesz ponownie zainstalować biblioteki.\n",
    "\n",
    "    Komórka 2:\n",
    "\n",
    "        Importuje biblioteki:\n",
    "\n",
    "            os: Do pracy ze zmiennymi środowiskowymi.\n",
    "\n",
    "            dotenv: Do ładowania zmiennych środowiskowych z pliku .env.\n",
    "\n",
    "            ChatGoogleGenerativeAI: Klasa do interakcji z modelami Gemini w Langchain.\n",
    "\n",
    "            PromptTemplate: Klasa do tworzenia promptów.\n",
    "\n",
    "            StrOutputParser: Klasa do konwersji wyniku modelu na string.\n",
    "\n",
    "        Ładuje zmienne środowiskowe z pliku .env.\n",
    "\n",
    "        Pobiera klucz API Google z zmiennej środowiskowej GOOGLE_API_KEY.\n",
    "\n",
    "        Sprawdza, czy klucz API został pobrany.\n",
    "\n",
    "        Inicjalizuje model ChatGoogleGenerativeAI.\n",
    "\n",
    "    Komórka 3:\n",
    "\n",
    "        Definiuje prompt template.\n",
    "\n",
    "        Tworzy łańcuch, łącząc prompt, model i parser wyjścia.\n",
    "\n",
    "        Uruchamia łańcuch za pomocą chain.invoke({}).\n",
    "\n",
    "        Wyświetla odpowiedź.\n",
    "\n",
    "Jak używać w Jupyter Notebook:\n",
    "\n",
    "    Otwórz plik ipynb w Jupyter Notebook.\n",
    "\n",
    "    Wklej zawartość każdej komórki do osobnej komórki w notebooku.\n",
    "\n",
    "    Uruchom komórki po kolei (Shift + Enter).\n",
    "\n",
    "Dodatkowe informacje:\n",
    "\n",
    "    Upewnij się, że masz aktywny kernel (jądro) Jupyter Notebook, który korzysta z Twojego środowiska wirtualnego.\n",
    "\n",
    "    Upewnij się, że plik .env znajduje się w tym samym katalogu co plik ipynb.\n",
    "\n",
    "    Upewnij się, że masz poprawny klucz API Google w pliku .env.\n",
    "\n",
    "    Ten kod powinien działać bez żadnych ostrzeżeń.\n",
    "\n",
    "Ten kod to kompletny przykład, który możesz skopiować i wkleić do Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Podsumowanie**\n",
    "LangChain pozwala budować **zaawansowane aplikacje AI** w prosty sposób. W kolejnych lekcjach nauczymy się, jak łączyć modele AI z bazami danych i API.\n",
    "\n",
    "🚀 **Teraz czas na praktykę!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
