{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lekcja 31: Wprowadzenie do LangChain i jego architektury**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Wstƒôp**\n",
    "LangChain to framework, kt√≥ry **upraszcza tworzenie aplikacji AI** opartych na **LLMs**. Umo≈ºliwia:\n",
    "- **≈ÅƒÖczenie modeli AI z danymi**\n",
    "- **Tworzenie chatbot√≥w**\n",
    "- **Automatyzacjƒô proces√≥w**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Instalacja LangChain**\n",
    "Kom√≥rka 1: Instalacja wymaganych bibliotek (uruchom tylko raz, je≈õli ich nie masz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (1.0.1)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (0.8.4)\n",
      "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
      "  Using cached langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.11.12-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Using cached numpy-2.2.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (2.160.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.67.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\takze\\onedrive\\pulpit\\bootcamp\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
      "Using cached aiohttp-3.11.12-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
      "Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Using cached numpy-2.2.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Installing collected packages: filetype, zstandard, tenacity, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain-google-genai\n",
      "Successfully installed SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 filetype-1.2.0 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.18 langchain-core-0.3.34 langchain-google-genai-2.0.9 langchain-text-splitters-0.3.6 langsmith-0.3.8 multidict-6.1.0 numpy-2.2.2 orjson-3.10.15 propcache-0.2.1 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.18.3 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv langchain langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Podstawowa architektura LangChain**\n",
    "LangChain sk≈Çada siƒô z 3 g≈Ç√≥wnych komponent√≥w:\n",
    "1. **LLMs** ‚Üí Model jƒôzykowy (np. GPT-4).\n",
    "2. **Prompt Engineering** ‚Üí Tworzenie skutecznych zapyta≈Ñ.\n",
    "3. **≈Åa≈Ñcuchy (Chains)** ‚Üí Automatyczne wykonywanie sekwencji operacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Przyk≈Çad kodu ‚Äì u≈ºycie LangChain do generowania tekstu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kom√≥rka 2: Import bibliotek, za≈Çadowanie klucza API i inicjalizacja modelu Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "# Za≈Çaduj zmienne ≈õrodowiskowe z pliku .env\n",
    "load_dotenv()\n",
    "\n",
    "# Pobierz klucz API Google z zmiennej ≈õrodowiskowej\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Sprawd≈∫ czy klucz API Google zosta≈Ç pobrany\n",
    "if google_api_key is None:\n",
    "    raise ValueError(\"Nie znaleziono klucza API Google. Upewnij siƒô, ≈ºe ustawi≈Çe≈õ zmiennƒÖ ≈õrodowiskowƒÖ GOOGLE_API_KEY w pliku .env.\")\n",
    "\n",
    "# Ustaw klucz API i zainicjuj model ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kom√≥rka 3: Definicja promptu i uruchomienie ≈Ça≈Ñcucha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain to framework u≈ÇatwiajƒÖcy tworzenie aplikacji opartych na du≈ºych modelach jƒôzykowych (LLM). Zapewnia on zestaw abstrakcji i narzƒôdzi upraszczajƒÖcych pracƒô z LLM, pozwalajƒÖc na budowƒô bardziej zaawansowanych i z≈Ço≈ºonych aplikacji.\n",
      "\n",
      "Oto g≈Ç√≥wne elementy dzia≈Çania LangChain:\n",
      "\n",
      "**1. Modele:**\n",
      "\n",
      "* **LLMs:** LangChain obs≈Çuguje integracjƒô z r√≥≈ºnymi dostawcami LLM, takimi jak OpenAI, Hugging Face, Cohere i innymi. Mo≈ºna ≈Çatwo prze≈ÇƒÖczaƒá siƒô miƒôdzy modelami i eksperymentowaƒá z r√≥≈ºnymi architekturami.\n",
      "* **Chat Models:**  LangChain oferuje specjalizowane wsparcie dla modeli konwersacyjnych, pozwalajƒÖc na budowanie chatbot√≥w i asystent√≥w. Umo≈ºliwia to zarzƒÖdzanie historiƒÖ konwersacji i definiowanie r√≥≈ºnych person dla bot√≥w.\n",
      "* **Text Embedding Models:**  LangChain integruje siƒô z modelami generujƒÖcymi wektory osadze≈Ñ tekstu, co umo≈ºliwia por√≥wnywanie semantyczne tekst√≥w i wyszukiwanie informacji.\n",
      "\n",
      "**2. ≈Åa≈Ñcuchy (Chains):**\n",
      "\n",
      "* **Sekwencyjne:** ≈Åa≈Ñcuchy sekwencyjne wykonujƒÖ seriƒô operacji jedna po drugiej.  Wynik jednego kroku jest przekazywany jako wej≈õcie do kolejnego.  Przyk≈Çadowo, mo≈ºna stworzyƒá ≈Ça≈Ñcuch, kt√≥ry najpierw podsumowuje tekst, a nastƒôpnie t≈Çumaczy go na inny jƒôzyk.\n",
      "* **R√≥wnoleg≈Çe:**  ≈Åa≈Ñcuchy r√≥wnoleg≈Çe wykonujƒÖ wiele operacji jednocze≈õnie.  Przyk≈Çadowo, mo≈ºna wys≈Çaƒá ten sam tekst do kilku r√≥≈ºnych LLM i por√≥wnaƒá ich odpowiedzi.\n",
      "\n",
      "**3. Indeksy:**\n",
      "\n",
      "* **Wektoryzacja i wyszukiwanie:** LangChain u≈Çatwia tworzenie indeks√≥w wektorowych dokument√≥w, co umo≈ºliwia szybkie i efektywne wyszukiwanie informacji na podstawie semantycznego podobie≈Ñstwa.\n",
      "* **≈ÅƒÖczenie z bazami danych:**  LangChain pozwala na ≈ÇƒÖczenie LLM z zewnƒôtrznymi ≈∫r√≥d≈Çami danych, takimi jak bazy danych SQL lub dokumenty.  Umo≈ºliwia to LLM dostƒôp do informacji spoza ich w≈Çasnej wiedzy.\n",
      "\n",
      "**4. Pamiƒôƒá:**\n",
      "\n",
      "* **Zachowywanie kontekstu:** LangChain oferuje mechanizmy pamiƒôci, kt√≥re pozwalajƒÖ LLM na zapamiƒôtywanie poprzednich interakcji i wykorzystywanie tej informacji w kolejnych odpowiedziach.  To kluczowe dla budowania sp√≥jnych i kontekstualnych konwersacji.\n",
      "* **R√≥≈ºne typy pamiƒôci:**  LangChain obs≈Çuguje r√≥≈ºne typy pamiƒôci, takie jak pamiƒôƒá kr√≥tkotrwa≈Ça (np. ostatnie kilka wypowiedzi) i d≈Çugotrwa≈Ça (np. informacje o u≈ºytkowniku).\n",
      "\n",
      "**5. Callbacks:**\n",
      "\n",
      "* **Monitorowanie i debugowanie:** Callbacks pozwalajƒÖ na monitorowanie dzia≈Çania ≈Ça≈Ñcuch√≥w i zbieranie informacji o ich wykonaniu.  U≈Çatwia to debugowanie i optymalizacjƒô aplikacji.\n",
      "\n",
      "**PodsumowujƒÖc:**\n",
      "\n",
      "LangChain dzia≈Ça poprzez ≈ÇƒÖczenie r√≥≈ºnych komponent√≥w, takich jak modele LLM, ≈Ça≈Ñcuchy, indeksy i pamiƒôƒá, w celu tworzenia zaawansowanych aplikacji opartych na jƒôzyku.  Framework ten upraszcza proces budowania, testowania i wdra≈ºania tych aplikacji, oferujƒÖc elastyczno≈õƒá i modularno≈õƒá.  Dziƒôki LangChain, deweloperzy mogƒÖ skupiƒá siƒô na logice aplikacji, zamiast na szczeg√≥≈Çach technicznych integracji z LLM.\n"
     ]
    }
   ],
   "source": [
    "# Utw√≥rz prompt template\n",
    "template = \"Jak dzia≈Ça LangChain?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Stw√≥rz ≈Ça≈Ñcuch\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Wykonaj zapytanie i uzyskaj odpowied≈∫\n",
    "response = chain.invoke({})\n",
    "\n",
    "# Wy≈õwietl odpowied≈∫\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyja≈õnienie:\n",
    "\n",
    "    Kom√≥rka 1: Instaluje wymagane biblioteki. Uruchom jƒÖ tylko raz, chyba ≈ºe chcesz ponownie zainstalowaƒá biblioteki.\n",
    "\n",
    "    Kom√≥rka 2:\n",
    "\n",
    "        Importuje biblioteki:\n",
    "\n",
    "            os: Do pracy ze zmiennymi ≈õrodowiskowymi.\n",
    "\n",
    "            dotenv: Do ≈Çadowania zmiennych ≈õrodowiskowych z pliku .env.\n",
    "\n",
    "            ChatGoogleGenerativeAI: Klasa do interakcji z modelami Gemini w Langchain.\n",
    "\n",
    "            PromptTemplate: Klasa do tworzenia prompt√≥w.\n",
    "\n",
    "            StrOutputParser: Klasa do konwersji wyniku modelu na string.\n",
    "\n",
    "        ≈Åaduje zmienne ≈õrodowiskowe z pliku .env.\n",
    "\n",
    "        Pobiera klucz API Google z zmiennej ≈õrodowiskowej GOOGLE_API_KEY.\n",
    "\n",
    "        Sprawdza, czy klucz API zosta≈Ç pobrany.\n",
    "\n",
    "        Inicjalizuje model ChatGoogleGenerativeAI.\n",
    "\n",
    "    Kom√≥rka 3:\n",
    "\n",
    "        Definiuje prompt template.\n",
    "\n",
    "        Tworzy ≈Ça≈Ñcuch, ≈ÇƒÖczƒÖc prompt, model i parser wyj≈õcia.\n",
    "\n",
    "        Uruchamia ≈Ça≈Ñcuch za pomocƒÖ chain.invoke({}).\n",
    "\n",
    "        Wy≈õwietla odpowied≈∫.\n",
    "\n",
    "Jak u≈ºywaƒá w Jupyter Notebook:\n",
    "\n",
    "    Otw√≥rz plik ipynb w Jupyter Notebook.\n",
    "\n",
    "    Wklej zawarto≈õƒá ka≈ºdej kom√≥rki do osobnej kom√≥rki w notebooku.\n",
    "\n",
    "    Uruchom kom√≥rki po kolei (Shift + Enter).\n",
    "\n",
    "Dodatkowe informacje:\n",
    "\n",
    "    Upewnij siƒô, ≈ºe masz aktywny kernel (jƒÖdro) Jupyter Notebook, kt√≥ry korzysta z Twojego ≈õrodowiska wirtualnego.\n",
    "\n",
    "    Upewnij siƒô, ≈ºe plik .env znajduje siƒô w tym samym katalogu co plik ipynb.\n",
    "\n",
    "    Upewnij siƒô, ≈ºe masz poprawny klucz API Google w pliku .env.\n",
    "\n",
    "    Ten kod powinien dzia≈Çaƒá bez ≈ºadnych ostrze≈ºe≈Ñ.\n",
    "\n",
    "Ten kod to kompletny przyk≈Çad, kt√≥ry mo≈ºesz skopiowaƒá i wkleiƒá do Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Podsumowanie**\n",
    "LangChain pozwala budowaƒá **zaawansowane aplikacje AI** w prosty spos√≥b. W kolejnych lekcjach nauczymy siƒô, jak ≈ÇƒÖczyƒá modele AI z bazami danych i API.\n",
    "\n",
    "üöÄ **Teraz czas na praktykƒô!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
